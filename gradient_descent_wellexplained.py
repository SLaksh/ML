# -*- coding: utf-8 -*-
"""Gradient Descent- WellExplained.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-wBcOuC9V3K3nTt1U-6y38g5FkdJ2xxa

# What is Gradient Descent

1.   Gradient Descent is a fundamental optimization algorithm used in machine learning and various other fields to minimize a function, typically a cost or loss function
2.   It’s an iterative algorithm that adjusts the model’s parameters to find the minimum of the function, which represents the best possible values for those parameters.

# **# How it works**

1. **Objective Function** : In ML here you want to minimize a cost or loss function, which measures the error between the model’s predictions and the actual target values.
2. **Initialization:**  which is done by selecting an initial guess for the parameters whihc can be random or set to some default values.
3. **Gradient Calculation**: It will be an iteration and at each iteration, you calculate the gradient of the objective function for the parameters where the gradient is a vector that points in the direction of the steepest increase in the function.
4. **Update Parameters**:  where the parameters are adjusted in the opposite direction of the gradient to move toward the minimum with size of this step is controlled by a parameter known as the learning rate. The update rule for a parameter θ is typically: **θ=θ−learning rate×∇f(θ)** Where ∇f(θ) is the gradient of the function at θ.
5. **Iterate**: Steps 3 and 4 are repeated iteratively until a stopping criterion which include reaching a certain number of iterations, achieving a specific level of convergence, or a combination of both.

# **#Variations in Gradient Descent**

1.   **Batch Gradient Descent**: where the entire dataset is used to compute the gradient at each iteration which can be computationally expensive for large datasets.
2. **Stochastic Gradient Descent (SGD)**: is where at each iteration, only a single data point or a **small random subset (mini-batch)** is used to compute the gradient. This introduces randomness and is faster and can escape local minima.
3.  **Mini-Batch Gradient Descent**: this is just a compromise between batch and stochastic gradient descent, where a **mini-batch of data points** is used to compute the gradient at each iteration.
4. **Adaptive Methods**: this is a kind of adaptive method, such as **Adagrad, RMSprop**, and **Adam**, adjust the learning rate during training to speed up convergence and deal with sparse data.

# **Applications  ***

*  **In ML**: To train neural networks and optimize the model’s parameters as NN involves many parameter, finding the optimal values that would minimise the prediction error- which is possible by the efficient covnergence of **GRADIENT DESCENT**

*  **In Deep NN**:  Variations like Stochastic Gradient Descent (SGD), Adam, and RMSprop have been developed to address specific challenges in training

*  **In Economics** : In estimating economic models, optimizing portfolios, and solving dynamic programming problems

*   **In Finance**: In risk management, option pricing, and algorithmic trading.

*   **In Engineering & Control systems**: in designing aerodynamic shapes, minimizing energy consumption in mechanical systems, and tuning controllers for stability and performance.

*   **In Physics & Simulation**: to solve complex physical systems by minimizing potential energy or maximizing entropy. It is also employed in simulations to study the behavior of physical systems over time.
"""

!pip install numpy matplotlib

import numpy as np
import matplotlib.pyplot as plt

# Define the objective function
def objective_function(x):
    return x**2

# Define the gradient of the objective function
def gradient(x):
    return 2 * x

# Gradient Descent function
def gradient_descent(learning_rate, iterations):
    x = 10  # Initial guess
    history = []  # To store the history of x values for plotting

# We store the history of x values during each iteration to track the trajectory.

    for _ in range(iterations):
        history.append(x)
        x = x - learning_rate * gradient(x)
    return history

# Set hyperparameters
learning_rate = 0.1
iterations = 20

# Run gradient descent
trajectory = gradient_descent(learning_rate, iterations)

# Plot the objective function and the trajectory
x = np.linspace(-12, 12, 400)
y = objective_function(x)

plt.figure(figsize=(10, 5))
plt.plot(x, y, label='Objective Function')
plt.plot(trajectory, [objective_function(x) for x in trajectory], 'ro-', label='Trajectory')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.title('Gradient Descent')
plt.legend()
plt.grid(True)
plt.show()